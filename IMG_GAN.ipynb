{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtP9UhpdqAgz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dcf9681-13cd-4b3a-9c35-f2f7382db166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "PbknIiWW8Ohg",
        "outputId": "0640bf03-5ebb-433a-e805-c7cde5013ef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-133c08f6-e275-46a4-bc07-554902dc3f36\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-133c08f6-e275-46a4-bc07-554902dc3f36\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"madhandev\",\"key\":\"1c65c54080ec9ddaaf7af8ec6d98ae74\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lha kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkkTZWga8X6m",
        "outputId": "6dd2348c-fc06-4c76-82ee-be49f359796e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 65 Dec  5 12:28 kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "zTbY0d6Y8eC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "DqSawiNw8p6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "K64a_ZWA8mBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Humans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbF7kz9I8t31",
        "outputId": "82c1cbbb-05df-4813-a6e2-2017b364bc17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Humans\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ODPEJgEa9IL3",
        "outputId": "414d900a-7b2f-44cf-819f-6a0b6116e922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Humans'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list\n"
      ],
      "metadata": {
        "id": "4f7jDHRj9PJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d ashwingupta3012/human-faces"
      ],
      "metadata": {
        "id": "lcaE8oCt9an-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip human-faces.zip"
      ],
      "metadata": {
        "id": "NCreycgV-Xk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4_0q0JypD2C"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-gpu==2.8.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoN4EibOpuIX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.preprocessing.image import array_to_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GIX-cTWpwV8"
      },
      "outputs": [],
      "source": [
        "gpus =tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJQKDfR0p3tT"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/MyDrive/Humans'\n",
        "img_list = ['jpeg', 'jpg', 'bmp', 'png']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJZP1V6op6ju"
      },
      "outputs": [],
      "source": [
        "for i in os.listdir(data_dir):\n",
        "    print(i)\n",
        "\n",
        "sample = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8qei3LKMPB6"
      },
      "outputs": [],
      "source": [
        "for i in os.listdir(data_dir):\n",
        "  image_path=os.path.join(data_dir,i);\n",
        "  try:\n",
        "    img=tf.keras.preprocessing.image.load_img(image_path)\n",
        "    img=tf.keras.preprocessing.image.img_to_array(img)\n",
        "    tip=img.dtype\n",
        "    if tip not in img_list:\n",
        "      print(\"Image type not in image list\")\n",
        "      print(i)\n",
        "      os.remove(image_path)\n",
        "  except Exception as e:\n",
        "    print(\"Issue {}\".format(e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzvkACaAqaLN",
        "outputId": "550e5687-28e9-4859-8cfe-32e2151374a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7219 files belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "data = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/Humans',\n",
        "    image_size=(256, 256),\n",
        "    shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCHYQheareHs"
      },
      "outputs": [],
      "source": [
        "data = data.map(lambda x, y: (x / 255, y))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFVTQiZb_kNe",
        "outputId": "03b03ef4-2777-47ea-a27d-796a40550057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1h0kItnB0cym"
      },
      "outputs": [],
      "source": [
        "scaled_itt=data.as_numpy_iterator()\n",
        "batch=scaled_itt.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4l6eGvv0lq6"
      },
      "outputs": [],
      "source": [
        "fig, ax =plt.subplots(ncols=4,figsize=(28,28))\n",
        "for idx,img in enumerate(batch[0][:4]):\n",
        "  ax[idx].imshow(img)\n",
        "  ax[idx].title.set_text(batch[1][idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQolLEF9rhEa"
      },
      "outputs": [],
      "source": [
        "def build_generator():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(256, input_dim=100, activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(512, activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(1024, activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(256 * 256 * 3, activation='sigmoid'))\n",
        "    model.add(layers.Reshape((256, 256, 3)))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyZo_0njrkM7"
      },
      "outputs": [],
      "source": [
        "generator = build_generator()\n",
        "random_noise = tf.random.normal((4, 100))\n",
        "generated_images = generator(random_noise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmbgGzXM03Jm",
        "outputId": "6335f188-1a01-429b-a69f-7c4fd48b2134"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 256, 256, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "generatore_images=generator(tf.random.normal((4,100)))\n",
        "generatore_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwoe70s_ttcF"
      },
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "  fake_img = generator(tf.random.normal((4, 100)), training=False)\n",
        "  print(fake_img)\n",
        "  print(i, \"end\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZB9gRV1gueIt",
        "outputId": "9bb64e91-843e-49ff-efd4-7871bf2dd135"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([32, 256, 256, 3])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fake_img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWOHKrX5rmsi"
      },
      "outputs": [],
      "source": [
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqlLcYZGrqF-"
      },
      "outputs": [],
      "source": [
        "def build_discriminator(in_shape):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Flatten(input_shape=in_shape))\n",
        "    model.add(layers.Dense(1024, activation='relu'))\n",
        "    model.add(layers.Dropout(0.4))  # Add dropout for regularization\n",
        "    model.add(layers.Dense(512, activation='relu'))\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Dense(256, activation='relu'))\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJSddTU7r0Y4"
      },
      "outputs": [],
      "source": [
        "in_shape = (256, 256, 3)\n",
        "discriminator = build_discriminator(in_shape)\n",
        "discriminator.summary()\n",
        "discriminator.predict(np.expand_dims(generated_images[0], 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbeFSnmT4I7T",
        "outputId": "48f7bd83-b643-4109-83fc-c2508194f35f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_from_generator = generator(tf.random.normal((32,100)), training=True)\n",
        "len(image_from_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pPyJEpEx-X0"
      },
      "outputs": [],
      "source": [
        "count=0\n",
        "while(count==0):\n",
        "  image_from_generator = generator(tf.random.normal((32,100)), training=True)\n",
        "  print(image_from_generator)\n",
        "  print(image_from_generator.shape)\n",
        "\n",
        "  prediction=discriminator(image_from_generator, training=True)\n",
        "  print(\"label\")\n",
        "  print(prediction)\n",
        "\n",
        "  image_from_generator *= 255\n",
        "  # image_from_generator = image_from_generator.astype('uint8')\n",
        "  for i in range(32):\n",
        "    img = array_to_img(image_from_generator[i])\n",
        "    img.save(os.path.join('/content/drive/MyDrive/GAN_generated_images', f'generated_img_{i}.png'))\n",
        "\n",
        "  for j in prediction:\n",
        "    if int(j[0])==0:\n",
        "      count=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yqvh-LV2v0oS"
      },
      "outputs": [],
      "source": [
        "imge=generator.predict(tf.random.normal((32,100)))\n",
        "imge.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wcbfBW7wKpQ",
        "outputId": "9bdd155b-aa0c-4161-d00a-35cfee9e1448"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_label=discriminator(imge, training=True)\n",
        "len(predicted_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpA6uBhXtYXF"
      },
      "outputs": [],
      "source": [
        "discriminator.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
        "                      loss='binary_crossentropy',  # Use binary cross-entropy for GANs\n",
        "                      metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzqvYs6Ur6f8"
      },
      "outputs": [],
      "source": [
        "class ModelCallback(Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=100):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gen_imgs = generator.predict(tf.random.normal((self.num_img, self.latent_dim)))\n",
        "        gen_imgs *= 255\n",
        "        gen_imgs = gen_imgs.astype('uint8')\n",
        "        for i in range(self.num_img):\n",
        "            img = array_to_img(gen_imgs[i])\n",
        "            img.save(os.path.join('/content/drive/MyDrive/gen_img', f'generated_img_{epoch}_{i}.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUpTiyh6sANe"
      },
      "outputs": [],
      "source": [
        "class GAN(models.Model):\n",
        "    def __init__(self, discriminator, generator, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "\n",
        "    def compile(self, g_opt, d_opt, g_loss, d_loss, *args, **kwargs):\n",
        "        super().compile(*args, **kwargs)\n",
        "        self.g_opt = g_opt\n",
        "        self.d_opt = d_opt\n",
        "        self.g_loss = g_loss\n",
        "        self.d_loss = d_loss\n",
        "\n",
        "    def train_step(self, batch):\n",
        "        real_img, real_img_label = batch\n",
        "        fake_img = self.generator(tf.random.normal((32, 100)), training=False)\n",
        "\n",
        "        # Train discriminator\n",
        "        with tf.GradientTape() as disc_tape:\n",
        "            what_real = self.discriminator(real_img, training=True)\n",
        "            what_fake = self.discriminator(fake_img, training=True)\n",
        "\n",
        "            what_real_fake = tf.concat([what_real, what_fake], axis=0)\n",
        "\n",
        "            # Create label\n",
        "            y_real_fake = tf.ones_like(what_real_fake)\n",
        "\n",
        "            # Noise\n",
        "            noise_real = 0.15 * tf.random.uniform(tf.shape(what_real))\n",
        "            noise_fake = -0.15 * tf.random.uniform(tf.shape(what_fake))\n",
        "\n",
        "            what_real_fake_noise_cal = tf.concat([what_real+noise_real, what_fake+noise_fake], axis=0)\n",
        "\n",
        "            # Calculate losses\n",
        "            total_d_loss = self.d_loss(y_real_fake, what_real_fake_noise_cal)\n",
        "\n",
        "        gradients_of_discriminator = disc_tape.gradient(total_d_loss, self.discriminator.trainable_variables)\n",
        "        self.d_opt.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
        "\n",
        "        # Train generator\n",
        "        with tf.GradientTape() as gen_tape:\n",
        "            gen_img = self.generator(tf.random.normal((32, 100)), training=True)\n",
        "            # Create the predicted label\n",
        "            predicted_label = self.discriminator(gen_img, training=True)\n",
        "            total_g_loss = self.g_loss(tf.ones_like(predicted_label), predicted_label)\n",
        "\n",
        "        # Apply backpropagation\n",
        "        gradients_of_generator = gen_tape.gradient(total_g_loss, self.generator.trainable_variables)\n",
        "        self.g_opt.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
        "\n",
        "        return {\n",
        "            'd_loss': total_d_loss,\n",
        "            'g_loss': total_g_loss\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x-lqH5zsEWu"
      },
      "outputs": [],
      "source": [
        "img_gan = GAN(discriminator, generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5dXRGyxsGze"
      },
      "outputs": [],
      "source": [
        "g_opt = optimizers.Adam(learning_rate=0.0001)\n",
        "d_opt = optimizers.Adam(learning_rate=0.00001)\n",
        "g_loss = tf.keras.losses.BinaryCrossentropy()\n",
        "d_loss = tf.keras.losses.BinaryCrossentropy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXLP17agsJ63"
      },
      "outputs": [],
      "source": [
        "img_gan.compile(g_opt, d_opt, g_loss, d_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlB9Q8DMsMbT"
      },
      "outputs": [],
      "source": [
        "callback = ModelCallback()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4sJEQLbsO1g"
      },
      "outputs": [],
      "source": [
        "hist = img_gan.fit(data, epochs=20, callbacks=[callback], batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KiBOXCyuYmH"
      },
      "outputs": [],
      "source": [
        "imgs = generator.predict(tf.random.normal((32, 100)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMQgjaul2LQL"
      },
      "outputs": [],
      "source": [
        "plt.suptitle('Loss')\n",
        "plt.plot(hist.history['d_loss'], label='d_loss')\n",
        "plt.plot(hist.history['g_loss'], label='g_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}